{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Langchain**\n",
    "LangChain is a framework designed to simplify the creation of applications using large language models. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Different Usecases of langchain**\n",
    "\n",
    "1. Personal Assistance \n",
    "2. Question Answering over Docs \n",
    "3. Chatbots \n",
    "4. Querying Tabular data \n",
    "5. Interacting with API’s \n",
    "5. Extraction \n",
    "6. Evaluation \n",
    "7. Summarization \n",
    "(Link: https://docs.langchain.com/docs/category/use-cases ) "
   ]
  },
  {
   "attachments": {
    "image_Wdy3ugH-thumbnail_webp-600x300.webp": {
     "image/webp": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Components of Langchain**\n",
    "\n",
    "![image_Wdy3ugH-thumbnail_webp-600x300.webp](attachment:image_Wdy3ugH-thumbnail_webp-600x300.webp)\n",
    "\n",
    "\n",
    "#### 1. Model I/O: Interface with language models. It consists of Prompts, Models, and Output parsers \n",
    "#### 2. Data connection: Interface with application-specific data sources with data transformers, text splitters, vector stores, and retrievers \n",
    "#### 3. Chains: Construct a sequence of calls with other components of the AI application. some examples of chains are sequential chains, summarization chain, and Retrieval Q&A Chains \n",
    "#### 4. Agents: LangChain provides Agents which allow applications to utilize a dynamic chain of calls to various tools, including LLMs, based on user input. \n",
    "#### 5. Memory: Persist application state between runs of a chain \n",
    "#### 6. Callbacks: Log and stream steps of sequential chains in order to run the chains efficiently and monitor the resources consumption "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Models I/O - The interface to the AI brains**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nSaturday'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-ada-001\", openai_api_key=openai_api_key)\n",
    "llm(\"What day comes after Friday?\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "\n",
    "chat = ChatOpenAI(temperature=1, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Why don't you just teleport there? I'm sure you have that option, right?\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\n",
    "    [\n",
    "        SystemMessage(content=\"You are an unhelpful AI bot that makes a joke at whatever the user says\"),\n",
    "        HumanMessage(content=\"I would like to go to New York, how should I do this?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You can build a ChatPromptTemplate from one or more MessagePromptTemplates.\\n You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, \\n which you can convert to a string or Message object, depending on whether you want to\\n   use the formatted value as input to an llm or chat model.\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''You can build a ChatPromptTemplate from one or more MessagePromptTemplates.\n",
    " You can use ChatPromptTemplate's format_prompt -- this returns a PromptValue, \n",
    " which you can convert to a string or Message object, depending on whether you want to\n",
    "   use the formatted value as input to an llm or chat model.'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also herr is an example of how we can use prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "template = (\n",
    "    \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")\n",
    "\n",
    "# get a chat completion from the formatted messages\n",
    "chat(\n",
    "    chat_prompt.format_prompt(\n",
    "        input_language=\"English\", output_language=\"French\", text=\"I love programming.\"\n",
    "    ).to_messages()\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Embedding Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hi! It's time for the beach\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your embedding is length 1536\n",
      "Here's a sample: [-0.00011466221621958539, -0.0031506523955613375, -0.0007831145194359124, -0.019504327327013016, -0.015125557780265808]...\n"
     ]
    }
   ],
   "source": [
    "text_embedding = embeddings.embed_query(text)\n",
    "print (f\"Your embedding is length {len(text_embedding)}\")\n",
    "print (f\"Here's a sample: {text_embedding[:5]}...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe statement is incorrect because tomorrow is Tuesday.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)\n",
    "\n",
    "# I like to use three double quotation marks for my prompts because it's easier to read\n",
    "prompt = \"\"\"\n",
    "Today is Monday, tomorrow is Wednesday.\n",
    "\n",
    "What is wrong with that statement?\n",
    "\"\"\"\n",
    "\n",
    "llm(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Think of it as an f-string in python but for prompts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Prompt: \n",
      "I really want to travel to Rome. What should I do there?\n",
      "\n",
      "Respond in one short sentence\n",
      "\n",
      "-----------\n",
      "LLM Output: Visit the Colosseum, the Pantheon, the Trevi Fountain, and the Vatican!\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)\n",
    "\n",
    "# Notice \"location\" below, that is a placeholder for another value later\n",
    "template = \"\"\"\n",
    "I really want to travel to {location}. What should I do there?\n",
    "\n",
    "Respond in one short sentence\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"location\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "final_prompt = prompt.format(location='Rome')\n",
    "\n",
    "print (f\"Final Prompt: {final_prompt}\")\n",
    "print (\"-----------\")\n",
    "print (f\"LLM Output: {llm(final_prompt)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Selectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''' \n",
    "An easy way to select from a series of examples that allow you to dynamic place in-context information into your prompt. Often used when your task is nuanced or you have a large list of examples.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"input\", \"output\"],\n",
    "    template=\"Example Input: {input}\\nExample Output: {output}\",\n",
    ")\n",
    "\n",
    "# Examples of locations that nouns are found\n",
    "examples = [\n",
    "    {\"input\": \"pirate\", \"output\": \"ship\"},\n",
    "    {\"input\": \"pilot\", \"output\": \"plane\"},\n",
    "    {\"input\": \"driver\", \"output\": \"car\"},\n",
    "    {\"input\": \"tree\", \"output\": \"ground\"},\n",
    "    {\"input\": \"bird\", \"output\": \"nest\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SemanticSimilarityExampleSelector will select examples that are similar to your input by semantic meaning\n",
    "\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    # This is the list of examples available to select from.\n",
    "    examples, \n",
    "    \n",
    "    # This is the embedding class used to produce embeddings which are used to measure semantic similarity.\n",
    "    OpenAIEmbeddings(openai_api_key=openai_api_key), \n",
    "    \n",
    "    # This is the VectorStore class that is used to store the embeddings and do a similarity search over.\n",
    "    FAISS, \n",
    "    \n",
    "    # This is the number of examples to produce.\n",
    "    k=7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_prompt = FewShotPromptTemplate(     \n",
    "    # The object that will help select examples\n",
    "    example_selector=example_selector,\n",
    "    \n",
    "    # Your prompt\n",
    "    example_prompt=example_prompt,\n",
    "    \n",
    "    # Customizations that will be added to the top and bottom of your prompt\n",
    "    prefix=\"Give the location an item is usually found in\",\n",
    "    suffix=\"Input: {noun}\\nOutput:\",\n",
    "    \n",
    "    # What inputs your prompt will receive\n",
    "    input_variables=[\"noun\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give the location an item is usually found in\n",
      "\n",
      "Example Input: driver\n",
      "Example Output: car\n",
      "\n",
      "Example Input: pilot\n",
      "Example Output: plane\n",
      "\n",
      "Example Input: bird\n",
      "Example Output: nest\n",
      "\n",
      "Example Input: tree\n",
      "Example Output: ground\n",
      "\n",
      "Example Input: pirate\n",
      "Example Output: ship\n",
      "\n",
      "Input: student\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "# Select a noun!\n",
    "my_noun = \"student\"\n",
    "print(similar_prompt.format(noun=my_noun))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' classroom'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(similar_prompt.format(noun=my_noun))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "A helpful way to format the output of a model. Usually used for structured output.\n",
    "\n",
    "Two big concepts:\n",
    "\n",
    "1. Format Instructions - A autogenerated prompt that tells the LLM how to format it's response based off your desired result\n",
    "\n",
    "2. Parser - A method which will extract your model's text output into a desired structure (usually json)(as the default output of the model is string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How you would like your response structured. This is basically a fancy prompt template\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"bad_string\", description=\"This a poorly formatted user input string\"),\n",
    "    ResponseSchema(name=\"good_string\", description=\"This is your response, a reformatted response\")\n",
    "]\n",
    "\n",
    "# How you would like to parse your output\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# See the prompt template you created for formatting\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print (format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a poorly formatted string from a user.\n",
      "Reformat it and make sure all the words are spelled correctly\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"bad_string\": string  // This a poorly formatted user input string\n",
      "\t\"good_string\": string  // This is your response, a reformatted response\n",
      "}\n",
      "```\n",
      "\n",
      "% USER INPUT:\n",
      "welcom to califonya!\n",
      "\n",
      "YOUR RESPONSE:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You will be given a poorly formatted string from a user.\n",
    "Reformat it and make sure all the words are spelled correctly\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "% USER INPUT:\n",
    "{user_input}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"user_input\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    "    template=template\n",
    ")\n",
    "\n",
    "promptValue = prompt.format(user_input=\"welcom to califonya!\")\n",
    "\n",
    "print(promptValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\n\\t\"bad_string\": \"welcom to califonya!\",\\n\\t\"good_string\": \"Welcome to California!\"\\n}\\n```'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_output = llm(promptValue)\n",
    "llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bad_string': 'welcom to califonya!', 'good_string': 'Welcome to California!'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(llm_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexes - Structuring documents to LLMs can work with them\n",
    "### Document Loaders\n",
    "Easy ways to import data from other sources. Shared functionality with OpenAI Plugins specifically retrieval plugins\n",
    "\n",
    "See a big list of document loaders here. A bunch more on Llama Index as well.\n",
    "other include BSHTMLLoader, PyPDF loader etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import HNLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = HNLoader(\"https://news.ycombinator.com/item?id=34422627\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 76 comments\n",
      "Here's a sample:\n",
      "\n",
      "Ozzie_osman 5 months ago  \n",
      "             | next [–] \n",
      "\n",
      "LangChain is awesome. For people not sure what it's doing, large language models (LLMs) are very Ozzie_osman 5 months ago  \n",
      "             | parent | next [–] \n",
      "\n",
      "Also, another library to check out is GPT Index (https://github.com/jerryjliu/gpt_index)\n"
     ]
    }
   ],
   "source": [
    "print (f\"Found {len(data)} comments\")\n",
    "print (f\"Here's a sample:\\n\\n{''.join([x.page_content[:150] for x in data[:2]])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Splitters\n",
    "Often times your document is too long (like a book) for your LLM. You need to split it up into chunks. Text splitters help with this.\n",
    "\n",
    "There are many ways you could split your text into chunks, experiment with different ones to see which is best for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n"
     ]
    }
   ],
   "source": [
    "# This is a long document we can split up.\n",
    "with open('data/Metaverse.txt') as f:\n",
    "    pg_work = f.read()\n",
    "    \n",
    "print (f\"You have {len([pg_work])} document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 150,\n",
    "    chunk_overlap  = 20,\n",
    ")\n",
    "\n",
    "texts = text_splitter.create_documents([pg_work])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 10 documents\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview:\n",
      "Technology is changing rapidly. Some of the latest buzz is around the metaverse. While this concept of the metaverse isn’t new, Facebook’s rebrand to \n",
      "\n",
      "rebrand to Meta has sparked interest and discussion about the virtual world. Along with Meta, several companies are at the forefront of metaverse\n"
     ]
    }
   ],
   "source": [
    "print (\"Preview:\")\n",
    "print (texts[0].page_content, \"\\n\")\n",
    "print (texts[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrievers\n",
    "Easy way to combine documents with language models.\n",
    "\n",
    "There are many different types of retrievers, the most widely supported is the VectoreStoreRetriever\n",
    "\n",
    "When we create embeddings, this retriever goes to the documents and search for the best matching documents and returns it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loader = TextLoader('data/Metaverse.txt')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Get embedding engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# Embedd your texts\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=None, metadata=None, vectorstore=<langchain.vectorstores.faiss.FAISS object at 0x174103a90>, search_type='similarity', search_kwargs={})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init your retriever. Asking for just 1 document back\n",
    "retriever = db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technology is changing rapidly. Some of the latest buzz is around the metaverse. While this concept of the metaverse isn’t new, Facebook’s rebrand to Meta has sparked interest and discussion about the\n",
      "\n",
      "While many ways to enter the metaverse already exist through a series of different worlds that all require their own entry, the vision is that it will all come together in the future to form one cohes\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(\"Name the technologies the author is text is talking about? \")\n",
    "print(\"\\n\\n\".join([x.page_content[:200] for x in docs[:2]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Technology is changing rapidly. Some of the latest buzz is around the metaverse. While this concept of the metaverse isn’t new, Facebook’s rebrand to Meta has sparked interest and discussion about the virtual world. Along with Meta, several companies are at the forefront of metaverse technology and making big developments in this interactive space. Learn more about the top metaverse companies and jobs you can explore now and in the future in this industry. \\n\\nWhat is the metaverse?\\nThe metaverse is an interactive virtual world accessed through virtual reality (VR) and augmented reality (AR). Once in the metaverse, users interact through avatars, which are digital representations of people who can socialize, engage in entertainment, and in some cases, live a life within the virtual world.', metadata={'source': 'data/Metaverse.txt'}),\n",
       " Document(page_content='While many ways to enter the metaverse already exist through a series of different worlds that all require their own entry, the vision is that it will all come together in the future to form one cohesive virtual world.', metadata={'source': 'data/Metaverse.txt'})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorStores\n",
    "Databases to store vectors. Most popular ones are Pinecone & Weaviate. More examples on OpenAIs retriever documentation. Chroma & FAISS are easy to work with locally.\n",
    "\n",
    "Conceptually, think of them as tables w/ a column for embeddings (vectors) and a column for metadata.\n",
    "\n",
    "Example\n",
    "\n",
    "                      *Embedding*\t             *Metadata*\n",
    "[-0.00015641732898075134, -0.003165106289088726, ...]\t{'date' : '1/2/23}  \n",
    "[-0.00035465431654651654, 1.4654131651654516546, ...]\t{'date' : '1/3/23}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "loader = TextLoader('data/Metaverse.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# Get embedding engine ready\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 2 documents\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(texts)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_list = embeddings.embed_documents([text.page_content for text in texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 2 embeddings\n",
      "Here's a sample of one: [-0.02129788988108513, -0.004692647427253205, -0.0015398741811255324]...\n"
     ]
    }
   ],
   "source": [
    "print (f\"You have {len(embedding_list)} embeddings\")\n",
    "print (f\"Here's a sample of one: {embedding_list[0][:3]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Memory**\n",
    "Helping LLMs remember information.\n",
    "\n",
    "Memory is a bit of a loose term. It could be as simple as remembering information you've chatted about in the past or more complicated information retrieval.\n",
    "\n",
    "We'll keep it towards the Chat Message use case. This would be used for chat bots.\n",
    "\n",
    "There are many types of memory, explore the documentation to see which one fits your use case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Message History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashutoshsharma/Documents/ASHUTOSH BLENHEIM CHALCOT/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "history.add_ai_message(\"hi!\")\n",
    "\n",
    "history.add_user_message(\"what is the capital of france?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='hi!', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='what is the capital of france?', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of France is Paris.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_response = chat(history.messages)\n",
    "ai_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='hi!', additional_kwargs={}, example=False),\n",
       " HumanMessage(content='what is the capital of france?', additional_kwargs={}, example=False),\n",
       " AIMessage(content='The capital of France is Paris.', additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.add_ai_message(ai_response.content)\n",
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The financial capital of France is also Paris. It is not only the political and cultural capital but also the economic center of the country. Paris is home to many major banks, financial institutions, and the French stock exchange.', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding another message\n",
    "history.add_user_message(\"what is its Financial Capital?\")\n",
    "\n",
    "chat(history.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chains**\n",
    "Combining different LLM calls and action automatically\n",
    "\n",
    "Ex: Summary #1, Summary #2, Summary #3 > Final Summary\n",
    "\n",
    "Check out this video explaining different summarization chain types\n",
    "\n",
    "There are many applications of chains search to see which are best for your use case.\n",
    "\n",
    " two of them are here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple Sequential Chains\n",
    "Easy chains where you can use the output of an LLM as an input into another. Good for breaking up tasks (and keeping your LLM focused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "llm = OpenAI(temperature=1, openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Your job is to come up with a classic dish from the area that the users suggests.\n",
    "% USER LOCATION\n",
    "{user_location}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n",
    "\n",
    "# Holds my 'location' chain\n",
    "location_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given a meal, give a short and simple recipe on how to make that dish at home.\n",
    "% MEAL\n",
    "{user_meal}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n",
    "\n",
    "# Holds my 'meal' chain\n",
    "meal_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mA classic dish from Indore is \"Jalebi and Bikaneri Bhujia\". It is a popular combination of spiced crunchy snacks and sweet syrup-soaked fried dough.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mJalebi Recipe:\n",
      "Ingredients:\n",
      "- 2 cups all-purpose flour\n",
      "- 1/2 teaspoon active dry yeast\n",
      "- 1/2 teaspoon ground cardamom\n",
      "- 1/4 teaspoon saffron threads\n",
      "- 1/4 teaspoon ground nutmeg\n",
      "- 1/2 cup warm water\n",
      "- 1/2 cup plain yogurt\n",
      "- 2 cups oil for frying\n",
      "\n",
      "Syrup:\n",
      "- 2 cups white sugar\n",
      "- 2 cups water\n",
      "- Squeeze of lemon juice\n",
      "\n",
      "\n",
      "Bhujia Recipe:\n",
      "- 2 cups chickpea flour\n",
      "- 2 tablespoons oil\n",
      "- 1 teaspoon ajwain\n",
      "- 2 teaspoons cumin powder\n",
      "- 2 teaspoons black pepper\n",
      "- 2 teaspoons fennel seeds\n",
      "- 2 teaspoons red chili powder\n",
      "- 1/2 teaspoon turmeric powder\n",
      "- 1/2 teaspoon baking soda\n",
      "- 1 teaspoon amchur powder\n",
      "- 3 tablespoons water\n",
      "- 1 teaspoon salt\n",
      "- 2 tablespoons ghee\n",
      "- 2 tablespoons chopped fresh coriander\n",
      "- 2 cups oil for frying\n",
      "\n",
      "Instructions:\n",
      "\n",
      "Jalebi:\n",
      "1. In a medium bowl, whisk together the flour, yeast, cardamom, saffron, and nutmeg.\n",
      "2.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "review = overall_chain.run(\"Indore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. **Summarization Chain**\n",
    "Easily run through long numerous documents and get a summary.\n",
    "\n",
    "For ver long runs, you can create a Summarization Chain which will create and store a summary of the history.\n",
    "##### Explore more about Chain Types except map_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"Technology is changing rapidly. Some of the latest buzz is around the metaverse. While this concept of the metaverse isn’t new, Facebook’s rebrand to Meta has sparked interest and discussion about the virtual world. Along with Meta, several companies are at the forefront of metaverse technology and making big developments in this interactive space. Learn more about the top metaverse companies and jobs you can explore now and in the future in this industry.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"What is the metaverse?\n",
      "The metaverse is an interactive virtual world accessed through virtual reality (VR) and augmented reality (AR). Once in the metaverse, users interact through avatars, which are digital representations of people who can socialize, engage in entertainment, and in some cases, live a life within the virtual world.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\"While many ways to enter the metaverse already exist through a series of different worlds that all require their own entry, the vision is that it will all come together in the future to form one cohesive virtual world.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a concise summary of the following:\n",
      "\n",
      "\n",
      "\" Interest in the metaverse has been renewed by the rebrand of Facebook to Meta, and various major companies are creating new developments in the virtual world space. Find out about the top metaverse organizations and occupations that can be pursued now and in the future.\n",
      "\n",
      " The metaverse is a virtual world accessed through VR and AR that allows users to interact and participate in activities using avatars, often allowing them to experience life in a digital space.\n",
      "\n",
      "\n",
      "\n",
      "Currently, there are multiple overlapping virtual worlds which require separate entry points. The ultimate vision is that these individual worlds will eventually merge into one cohesive metaverse.\"\n",
      "\n",
      "\n",
      "CONCISE SUMMARY:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Interest in the metaverse, a virtual world capable of being accessed through VR and AR, has been renewed due to the rebrand of Facebook to Meta, and various major companies have since begun investing in new developments in the virtual world space. For those interested in pursuing a career in the metaverse, this article highlights several top metaverse organizations as well as occupations that can be undertaken both now and in the future, as the metaverse ultimately aims to merge all separate virtual worlds into one cohesive metaverse.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = TextLoader('data/Metaverse.txt')\n",
    "documents = loader.load()\n",
    "\n",
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "# # There is a lot of complexity hidden in this one line. I encourage you to check out the video above for more detail\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)\n",
    "chain.run(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Agents** \n",
    "Official LangChain Documentation describes agents perfectly (emphasis mine):\n",
    "\n",
    "Some applications will require not just a predetermined chain of calls to LLMs/other tools, but potentially an unknown chain that depends on the user's input. In these types of chains, there is a “agent” which has access to a suite of tools. Depending on the user input, the agent can then decide which, if any, of these tools to call.\n",
    "\n",
    "Basically you use the LLM not just for text output, but also for decision making. The coolness and power of this functionality can't be overstated enough.\n",
    "\n",
    "Sam Altman emphasizes that the LLMs are good 'reasoning engine'. Agent take advantage of this.\n",
    "\n",
    "### Agents\n",
    "The language model that drives decision making.\n",
    "\n",
    "More specifically, an agent takes in an input and returns a response corresponding to an action to take along with an action input. You can see different types of agents (which are better for different use cases) here.\n",
    "\n",
    "### Tools\n",
    "A 'capability' of an agent. This is an abstraction on top of a function that makes it easy for LLMs (and agents) to interact with it. Ex: Google search.\n",
    "\n",
    "This area shares commonalities with OpenAI plugins.\n",
    "\n",
    "### Toolkit\n",
    "Groups of tools that your agent can select from\n",
    "\n",
    "Let's bring them all together:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "serpapi_api_key = os.getenv(\"SERP_API\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "\n",
    "toolkit = load_tools([\"serpapi\"], llm=llm, serpapi_api_key=serpapi_api_key)\n",
    "\n",
    "agent = initialize_agent(toolkit, llm, agent=\"zero-shot-react-description\", verbose=True, return_intermediate_steps=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new  chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I should try to find out what band Natalie Bergman is a part of.\n",
      "Action: Search\n",
      "Action Input: \"Natalie Bergman band\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNatalie Bergman is an American singer-songwriter. She is one half of the duo Wild Belle, along with her brother Elliot Bergman. Her debut solo album, Mercy, was released on Third Man Records on May 7, 2021. She is based in Los Angeles.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should search for the debut album of Wild Belle.\n",
      "Action: Search\n",
      "Action Input: \"Wild Belle debut album\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mIsles\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Isles is the debut album of Wild Belle, the band that Natalie Bergman is a part of.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent({\"input\":\"what was the first album of the\" \n",
    "                    \"band that Natalie Bergman is a part of?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AgentAction(tool='Search', tool_input='Natalie Bergman band', log=' I should try to find out what band Natalie Bergman is a part of.\\nAction: Search\\nAction Input: \"Natalie Bergman band\"'),\n",
       " 'Natalie Bergman is an American singer-songwriter. She is one half of the duo Wild Belle, along with her brother Elliot Bergman. Her debut solo album, Mercy, was released on Third Man Records on May 7, 2021. She is based in Los Angeles.')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"intermediate_steps\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(AgentAction(tool='Search', tool_input='Natalie Bergman band', log=' I should try to find out what band Natalie Bergman is a part of.\\nAction: Search\\nAction Input: \"Natalie Bergman band\"'),\n",
      "  'Natalie Bergman is an American singer-songwriter. She is one half of the '\n",
      "  'duo Wild Belle, along with her brother Elliot Bergman. Her debut solo '\n",
      "  'album, Mercy, was released on Third Man Records on May 7, 2021. She is '\n",
      "  'based in Los Angeles.'),\n",
      " (AgentAction(tool='Search', tool_input='Wild Belle debut album', log=' I should search for the debut album of Wild Belle.\\nAction: Search\\nAction Input: \"Wild Belle debut album\"'),\n",
      "  'Isles')]\n"
     ]
    }
   ],
   "source": [
    "import pprint         \n",
    "pprint.pprint(response[\"intermediate_steps\"])       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents\n",
    "used to store documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documents\n",
    "from langchain.schema import Document\n",
    "doc = Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
    "         metadata={\n",
    "             'my_document_id' : 234234,\n",
    "             'my_document_source' : \"The LangChain Papers\",\n",
    "             'my_document_create_time' : 1680013019\n",
    "         })\n",
    "doc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
